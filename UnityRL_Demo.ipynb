{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91ec0fc",
   "metadata": {},
   "source": [
    "## Create the Environment Binary File\n",
    "Download the unity project from: https://drive.google.com/file/d/1Zjan3xYI-agsXPgfM9AVHc3ySF9j70Rr/view?usp=sharing\n",
    "\n",
    "* Goto 'build settings' in 'file'\n",
    "* Select the target platform and architecture\n",
    "* Click on 'Build'\n",
    "* Save the file as 'Roller_Ball_Build'\n",
    "* Copy this notebook to the directory of binary file\n",
    "\n",
    "## Installation:\n",
    "Python version: 3.8.10\n",
    "ML Agents:\n",
    "\n",
    "    pip install mlagents==0.16.1\n",
    "    \n",
    "\n",
    "ML Agents documentation: https://github.com/Unity-Technologies/ml-agents/blob/release_2/docs/Python-API.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924db715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlagents\n",
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2a093",
   "metadata": {},
   "source": [
    "### Loading the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ae4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change worker ID if currently mentioned worker is busy\n",
    "env = UE(file_name='Roller_Ball_Build', seed=1, side_channels=[], worker_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38bdfbac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08362276",
   "metadata": {},
   "source": [
    "### Get Behaviour Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8fd11b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RollerBall?team=0\n"
     ]
    }
   ],
   "source": [
    "behavior_names = env.get_behavior_names()\n",
    "behavior_name = behavior_names[0]\n",
    "print(behavior_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98accbcc",
   "metadata": {},
   "source": [
    "### Get Behaviour Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16572f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :  1\n"
     ]
    }
   ],
   "source": [
    "spec = env.get_behavior_spec(behavior_name = behavior_name)\n",
    "print(\"Number of observations : \", len(spec.observation_shapes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d72ba7",
   "metadata": {},
   "source": [
    "### Checking if Action is Continuous or Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f44b49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The action is continuous\n"
     ]
    }
   ],
   "source": [
    "if spec.is_action_continuous():\n",
    "  print(\"The action is continuous\")\n",
    "\n",
    "if spec.is_action_discrete():\n",
    "  print(\"The action is discrete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c260b1",
   "metadata": {},
   "source": [
    "### Sample Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c4171e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[3.9974775, 0.5      , 2.1941023, 0.       , 0.5      , 0.       ,\n",
      "        0.       , 0.       ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "decision_steps, terminal_steps = env.get_steps(behavior_name = behavior_name)\n",
    "print(decision_steps.obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e188035",
   "metadata": {},
   "source": [
    "### Take Random Actions and get Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab53da16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rewards for episode 1 is 1.0\n",
      "Total rewards for episode 2 is 1.0\n",
      "Total rewards for episode 3 is 0.0\n",
      "Total rewards for episode 4 is 0.0\n",
      "Total rewards for episode 5 is 0.0\n",
      "Total rewards for episode 6 is 0.0\n",
      "Total rewards for episode 7 is 1.0\n",
      "Total rewards for episode 8 is 0.0\n",
      "Total rewards for episode 9 is 1.0\n",
      "Total rewards for episode 10 is 0.0\n",
      "Total rewards for episode 11 is 0.0\n",
      "Total rewards for episode 12 is 0.0\n",
      "Total rewards for episode 13 is 1.0\n",
      "Total rewards for episode 14 is 0.0\n",
      "Total rewards for episode 15 is 0.0\n",
      "Total rewards for episode 16 is 0.0\n",
      "Total rewards for episode 17 is 0.0\n",
      "Total rewards for episode 18 is 0.0\n",
      "Total rewards for episode 19 is 0.0\n",
      "Total rewards for episode 20 is 0.0\n",
      "Total rewards for episode 21 is 1.0\n",
      "Total rewards for episode 22 is 0.0\n",
      "Total rewards for episode 23 is 1.0\n",
      "Total rewards for episode 24 is 0.0\n",
      "Total rewards for episode 25 is 0.0\n",
      "Total rewards for episode 26 is 0.0\n",
      "Total rewards for episode 27 is 0.0\n",
      "Total rewards for episode 28 is 1.0\n",
      "Total rewards for episode 29 is 0.0\n",
      "Total rewards for episode 30 is 0.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(30):\n",
    "  env.reset()\n",
    "  decision_steps, terminal_steps = env.get_steps(behavior_names[0])\n",
    "  tracked_agent = -1 # -1 indicates not yet tracking\n",
    "  done = False # For the tracked_agent\n",
    "  episode_rewards = 0 # For the tracked_agent\n",
    "  while not done:\n",
    "    # Track the first agent we see if not tracking\n",
    "    # Note : len(decision_steps) = [number of agents that requested a decision]\n",
    "    if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "      tracked_agent = decision_steps.agent_id[0]\n",
    "    # Generate an action for all agents\n",
    "    action = spec.create_empty_action(len(decision_steps))\n",
    "    action = np.random.normal(0, 1, size = np.shape(action))\n",
    "    # Set the actions\n",
    "    env.set_actions(behavior_name, action)\n",
    "    # Move the simulation forward\n",
    "    env.step()\n",
    "    # Get the new simulation results\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    if tracked_agent in decision_steps: # The agent requested a decision\n",
    "      episode_rewards += decision_steps[tracked_agent].reward\n",
    "    if tracked_agent in terminal_steps: # The agent terminated its episode\n",
    "      episode_rewards += terminal_steps[tracked_agent].reward\n",
    "      done = True\n",
    "  print(f\"Total rewards for episode {episode+1} is {episode_rewards}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9724359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed environment\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "print(\"Closed environment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
